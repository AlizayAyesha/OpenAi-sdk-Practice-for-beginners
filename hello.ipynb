{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agents\n",
    "agents in essence are llms that accomplish a specific task they can be supplemented with tools structured output and handoff to other agents\n",
    "- **Agent**: An agent is a self -contained, self-aware, and self-governing entity that can interact with its environment and make decisions based on its own goals and motivations. In the context of AI, an agent is a program that can perceive its environment, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai-agents in .\\venv\\lib\\site-packages (0.0.19)\n",
      "Requirement already satisfied: qU in .\\venv\\lib\\site-packages (1.2.5)\n",
      "Requirement already satisfied: griffe<2,>=1.5.6 in .\\venv\\lib\\site-packages (from openai-agents) (1.7.3)\n",
      "Requirement already satisfied: mcp<2,>=1.9.4 in .\\venv\\lib\\site-packages (from openai-agents) (1.9.4)\n",
      "Requirement already satisfied: openai>=1.87.0 in .\\venv\\lib\\site-packages (from openai-agents) (1.90.0)\n",
      "Requirement already satisfied: pydantic<3,>=2.10 in .\\venv\\lib\\site-packages (from openai-agents) (2.11.7)\n",
      "Requirement already satisfied: requests<3,>=2.0 in .\\venv\\lib\\site-packages (from openai-agents) (2.32.4)\n",
      "Requirement already satisfied: types-requests<3,>=2.0 in .\\venv\\lib\\site-packages (from openai-agents) (2.32.4.20250611)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.12.2 in .\\venv\\lib\\site-packages (from openai-agents) (4.14.0)\n",
      "Requirement already satisfied: colorama>=0.4 in .\\venv\\lib\\site-packages (from griffe<2,>=1.5.6->openai-agents) (0.4.6)\n",
      "Requirement already satisfied: anyio>=4.5 in .\\venv\\lib\\site-packages (from mcp<2,>=1.9.4->openai-agents) (4.9.0)\n",
      "Requirement already satisfied: httpx-sse>=0.4 in .\\venv\\lib\\site-packages (from mcp<2,>=1.9.4->openai-agents) (0.4.0)\n",
      "Requirement already satisfied: httpx>=0.27 in .\\venv\\lib\\site-packages (from mcp<2,>=1.9.4->openai-agents) (0.28.1)\n",
      "Requirement already satisfied: pydantic-settings>=2.5.2 in .\\venv\\lib\\site-packages (from mcp<2,>=1.9.4->openai-agents) (2.9.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.9 in .\\venv\\lib\\site-packages (from mcp<2,>=1.9.4->openai-agents) (0.0.20)\n",
      "Requirement already satisfied: sse-starlette>=1.6.1 in .\\venv\\lib\\site-packages (from mcp<2,>=1.9.4->openai-agents) (2.3.6)\n",
      "Requirement already satisfied: starlette>=0.27 in .\\venv\\lib\\site-packages (from mcp<2,>=1.9.4->openai-agents) (0.47.0)\n",
      "Requirement already satisfied: uvicorn>=0.23.1 in .\\venv\\lib\\site-packages (from mcp<2,>=1.9.4->openai-agents) (0.34.3)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in .\\venv\\lib\\site-packages (from pydantic<3,>=2.10->openai-agents) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in .\\venv\\lib\\site-packages (from pydantic<3,>=2.10->openai-agents) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in .\\venv\\lib\\site-packages (from pydantic<3,>=2.10->openai-agents) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in .\\venv\\lib\\site-packages (from requests<3,>=2.0->openai-agents) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in .\\venv\\lib\\site-packages (from requests<3,>=2.0->openai-agents) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in .\\venv\\lib\\site-packages (from requests<3,>=2.0->openai-agents) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in .\\venv\\lib\\site-packages (from requests<3,>=2.0->openai-agents) (2025.6.15)\n",
      "Requirement already satisfied: qiniu>=7.2.0 in .\\venv\\lib\\site-packages (from qU) (7.16.0)\n",
      "Requirement already satisfied: click>=6.7 in .\\venv\\lib\\site-packages (from qU) (8.2.1)\n",
      "Requirement already satisfied: pytest>=3.3.1 in .\\venv\\lib\\site-packages (from qU) (8.4.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in .\\venv\\lib\\site-packages (from anyio>=4.5->mcp<2,>=1.9.4->openai-agents) (1.3.1)\n",
      "Requirement already satisfied: httpcore==1.* in .\\venv\\lib\\site-packages (from httpx>=0.27->mcp<2,>=1.9.4->openai-agents) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in .\\venv\\lib\\site-packages (from httpcore==1.*->httpx>=0.27->mcp<2,>=1.9.4->openai-agents) (0.16.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in .\\venv\\lib\\site-packages (from openai>=1.87.0->openai-agents) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in .\\venv\\lib\\site-packages (from openai>=1.87.0->openai-agents) (0.10.0)\n",
      "Requirement already satisfied: tqdm>4 in .\\venv\\lib\\site-packages (from openai>=1.87.0->openai-agents) (4.67.1)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in .\\venv\\lib\\site-packages (from pydantic-settings>=2.5.2->mcp<2,>=1.9.4->openai-agents) (1.1.0)\n",
      "Requirement already satisfied: iniconfig>=1 in .\\venv\\lib\\site-packages (from pytest>=3.3.1->qU) (2.1.0)\n",
      "Requirement already satisfied: packaging>=20 in .\\venv\\lib\\site-packages (from pytest>=3.3.1->qU) (25.0)\n",
      "Requirement already satisfied: pluggy<2,>=1.5 in .\\venv\\lib\\site-packages (from pytest>=3.3.1->qU) (1.6.0)\n",
      "Requirement already satisfied: pygments>=2.7.2 in .\\venv\\lib\\site-packages (from pytest>=3.3.1->qU) (2.19.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install openai-agents qU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "api_key=os.environ.get(\"OPENAI_API_KEY\")\n",
    "\n",
    "if not api_key:\n",
    "    raise ValueError(\"OPENAI_API_KEY is not set in the enviroment variables\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello there! I'm as chipper as a freshly compiled program—always ready to help and throw in a dash of wit. How are you doing on your end?\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from agents import Agent, Runner\n",
    "\n",
    "agent = Agent(\n",
    "    name=\"Basic Agent\",\n",
    "    instructions=\"you are a helping assistant. respond in witty and informative ways.\",\n",
    "    model=\"o3-mini\"\n",
    ")\n",
    "\n",
    "result = await Runner.run(agent,\"Hello! How are you?\")\n",
    "result.final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Why did the AI agent break up with the computer?\\n\\nIt couldn't handle all the bytes!\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joke_agent = Agent(\n",
    "    name=\"Joke Agent\",\n",
    "    instructions=\"You are a joke teller. You are given a topic and you need to tell a joke about it\",\n",
    "\n",
    ")\n",
    "\n",
    "topic= \"AI Agent\"\n",
    "result = await Runner.run(joke_agent, topic)\n",
    "result.final_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orignal joke:\n",
      "Why don't AI agents ever get lost?\n",
      "\n",
      "Because they always follow the algorithms, even when they can’t “byte” off more than they can chew!\n",
      "\n",
      "Translated joke :\n",
      "¿Por qué los agentes de inteligencia artificial nunca se pierden?\n",
      "\n",
      "Porque siempre siguen los algoritmos, ¡incluso cuando no pueden \"morder\" más de lo que pueden masticar!\n"
     ]
    }
   ],
   "source": [
    "language_agent = Agent(\n",
    "            name=\"Language Agent\",\n",
    "    instructions=\"You are a language expert. you are given a joke and you need to rewrite it in a different language.\",\n",
    "\n",
    ")\n",
    "\n",
    "joke_result = await Runner.run(joke_agent,topic)\n",
    "translated_result =await Runner.run(language_agent, f\"translate this joke to spanish {joke_result.final_output}\")\n",
    "print(f\"Orignal joke:\\n{joke_result.final_output}\\n\")\n",
    "print(f\"Translated joke :\\n{translated_result.final_output}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structured Outputs\n",
    "\n",
    "Structured outputs are a way to format the output of an llm in a structured manner. this can be useful for specific formating or data extraction . the structured output is a dictionary that contains the output of the llm. the keys of the dictionary are the names of the output fields.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lyricist(title='Whispers of the Ancient Isles', content=\"(Verse 1)\\nIn the morning light, by the misty glen,\\nWhere the heather blooms, and the wild birds wend,\\nHear the call, oh sister, come close, draw near,\\nThe echoes of our mothers in the whispers of the year.\\n\\n(Chorus)\\nDance, oh daughters of the isle,\\nWith strength and grace, with courage smile.\\nThe ancient winds sing tales untold,\\nOf warrior hearts and souls of gold.\\n\\n(Verse 2)\\nBeneath the oak, where the shadows play,\\nIn the setting sun, feel the old ways sway.\\nGather 'round the fire, let the story spin,\\nWith laughter and tears, let the magic begin.\\n\\n(Chorus)\\nDance, oh daughters of the isle,\\nWith strength and grace, with courage smile.\\nThe ancient winds sing tales untold,\\nOf warrior hearts and souls of gold.\\n\\n(Bridge)\\nIn the whispering woods, where the faeries hide,\\nHear the songs of yore with the ocean's tide.\\nSing in harmony, with the moon's soft glow,\\nFor the spirit of the guardians in the lochs below.\\n\\n(Verse 3)\\nThrough the stormy nights and the peaceful dawn,\\nOur voices rise, in ancient tongues drawn.\\nTogether we stand, in strength, in might,\\nOh, daughters of the celtic light.\\n\\n(Chorus)\\nDance, oh daughters of the isle,\\nWith strength and grace, with courage smile.\\nThe ancient winds sing tales untold,\\nOf warrior hearts and souls of gold.\\n\\n(Outro)\\nSo sing, oh sisters, let the legends fly,\\nWith every breath, beneath the Celtic sky.\\nFor in our songs, the legacy finds,\\nA sacred bond through eternal kinds.\", lines_timing=4, repeataion_of_lyrics=3)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pydantic import BaseModel\n",
    "from agents import Agent, Runner\n",
    "\n",
    "# Define schema\n",
    "class Lyricist(BaseModel):\n",
    "    title: str\n",
    "    content: str\n",
    "    lines_timing: int  # in minutes\n",
    "    repeataion_of_lyrics: int\n",
    "\n",
    "# Define agent\n",
    "lyricist_agent = Agent(\n",
    "    name=\"Lyricist\",\n",
    "    instructions=(\n",
    "        \"You are an agent for creating song lyrics. \"\n",
    "        \"You will be given the theme of the song and your job is to output that as actual detailed lyrics. \"\n",
    "        \"Also provide lyrics duration and repeatation in minutes.\"\n",
    "    ),\n",
    "    output_type=Lyricist\n",
    ")\n",
    "\n",
    "\n",
    "response = await Runner.run(\n",
    "    lyricist_agent,\n",
    "    \"Write a Celtic-style song for women\"\n",
    ")\n",
    "\n",
    "response.final_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tool Calling\n",
    "\n",
    "Tool calling is a way to extend the capabilities of an llm by allowing it to call external tools or APIs. This can be useful for tasks that require specializad knowledge or access to external data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting weather for Dallas\n",
      "Getting temprature for Dallas\n",
      "The weather in Dallas is sunny with a temperature of 25 degrees.\n"
     ]
    }
   ],
   "source": [
    "from agents import Agent, function_tool \n",
    "\n",
    "# Define a simple weather tool\n",
    "@function_tool\n",
    "def get_weather(city: str) -> str:\n",
    "    print(f\"Getting weather for {city}\")\n",
    "    return f\"The weather in {city} is sunny.\"\n",
    "\n",
    "@function_tool\n",
    "def get_temperature(city: str) -> str:\n",
    "    print(f\"Getting temprature for {city}\")\n",
    "    return f\"The temperature in {city} is 25 degrees.\"\n",
    "\n",
    "# Create an agent that uses the tool\n",
    "agent = Agent(\n",
    "    name=\"weather_agent\",\n",
    "    instructions=(\n",
    "        \"You are the local weather and temprture agent. You are given the city name and \"\n",
    "        \"you must return the weather and temprture for that city.\"\n",
    "    ),\n",
    "    tools=[get_weather, get_temperature]\n",
    ")\n",
    "\n",
    "# Jupyter/Colab-compatible run\n",
    "result = await Runner.run(agent, input=\"What is the weather for Dallas?\")\n",
    "print(result.final_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a summary of the latest global news as of June 21, 2025:\n",
      "\n",
      "**Middle East Conflict**\n",
      "\n",
      "- **Israel-Iran War**: The conflict has entered its second week with intensified hostilities. Israeli airstrikes have targeted military infrastructure in Iran, including a nuclear research facility near Isfahan. Diplomatic negotiations in Geneva have stalled, with Iran refusing further talks while under attack. The U.S. is considering its level of military involvement, and European nations are evacuating their citizens from the region. ([apnews.com](https://apnews.com/article/894a8cfb8bf2c1b717e0a955f22b91e0?utm_source=openai))\n",
      "\n",
      "- **Turkey's Stance**: Turkish Foreign Minister Hakan Fidan has called for Islamic countries to unite against Israel's actions, describing them as an \"Israeli problem\" that threatens regional stability. ([apnews.com](https://apnews.com/article/894a8cfb8bf2c1b717e0a955f22b91e0?utm_source=openai))\n",
      "\n",
      "**European Affairs**\n",
      "\n",
      "- **Poland's Presidential Runoff**: Exit polls indicate a near tie in Poland's presidential runoff election, leaving the outcome too close to call. ([wsls.com](https://www.wsls.com/news/world/?utm_source=openai))\n",
      "\n",
      "- **France's Defense Strategy**: France is advocating for the European Union to strengthen the euro as a global reserve currency, aiming to reduce reliance on the U.S. dollar. ([ft.com](https://www.ft.com/content/7b3d9fd3-7b64-4600-95e0-f8ea1a1ff643?utm_source=openai))\n",
      "\n",
      "**Asia-Pacific Developments**\n",
      "\n",
      "- **China's Retirement Age**: China's legislature has approved raising the retirement age, which is currently among the lowest for major economies. ([abcnews.go.com](https://abcnews.go.com/international/?utm_source=openai))\n",
      "\n",
      "- **North Korea's Missile Test**: North Korea has announced the testing of a hypersonic intermediate-range missile, escalating regional tensions. ([nbcnews.com](https://www.nbcnews.com/?utm_source=openai))\n",
      "\n",
      "**Humanitarian Concerns**\n",
      "\n",
      "- **Gaza Aid Tragedy**: At least 31 Palestinians were killed and over 170 wounded while on their way to receive food aid in Gaza. Health officials and witnesses report the incident, while Israel denies responsibility. ([wsls.com](https://www.wsls.com/news/world/?utm_source=openai))\n",
      "\n",
      "- **Floods in Nigeria and India**: Severe flooding in Nigeria's Niger State has resulted in at least 150 deaths, with many more missing. In India's northeast, relentless monsoon rains have caused floods and landslides, leading to dozens of fatalities. ([aljazeera.com](https://www.aljazeera.com/news/?utm_source=openai))\n",
      "\n",
      "**U.S. Political Developments**\n",
      "\n",
      "- **Trump's Deliberation on Iran**: U.S. President Donald Trump is considering whether to support Israel in its military actions against Iran, with a decision expected within two weeks. This situation recalls the 2003 Iraq invasion and challenges Trump's commitment to ending prolonged U.S. military engagements. ([ft.com](https://www.ft.com/content/7b3d9fd3-7b64-4600-95e0-f8ea1a1ff643?utm_source=openai))\n",
      "\n",
      "- **SEC Regulatory Changes**: New SEC Chair Paul Atkins has reversed 14 regulatory proposals introduced by former Chair Gary Gensler, indicating a shift toward lighter regulation. ([ft.com](https://www.ft.com/content/7b3d9fd3-7b64-4600-95e0-f8ea1a1ff643?utm_source=openai))\n",
      "\n",
      "**Science and Technology**\n",
      "\n",
      "- **NASA's Mars Sample Return Plan**: NASA has overhauled its plan to bring samples from Mars back to Earth, aiming to ensure the success of this ambitious mission. ([nbcnews.com](https://www.nbcnews.com/?utm_source=openai))\n",
      "\n",
      "- **Lead Pollution in Ancient Rome**: A recent study suggests that lead pollution in ancient Rome may have lowered the average IQ of its population, highlighting the long-term effects of environmental contamination. ([nbcnews.com](https://www.nbcnews.com/?utm_source=openai))\n",
      "\n",
      "Please note that the situation is evolving rapidly, and it's advisable to consult multiple sources for the most current information.\n",
      "\n",
      "\n",
      "## Key Developments in Global Affairs:\n",
      "- [The Latest: Israel-Iran war enters a second week with renewed strikes](https://apnews.com/article/894a8cfb8bf2c1b717e0a955f22b91e0?utm_source=openai)\n",
      "- [FirstFT: Donald Trump deliberates on Iran attack](https://www.ft.com/content/7b3d9fd3-7b64-4600-95e0-f8ea1a1ff643?utm_source=openai) \n"
     ]
    }
   ],
   "source": [
    "from agents import WebSearchTool\n",
    "news_agent = Agent(\n",
    "    name=\"News Reporter\",\n",
    "    instructions=\"You are a news reporter. Find the latest news globally.\",\n",
    "    tools=[WebSearchTool()] \n",
    ")\n",
    "\n",
    "# Run the agent\n",
    "result = await Runner.run(news_agent, input=\"What is the latest news in the world?\")\n",
    "print(result.final_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HandsOffs\n",
    "\n",
    " HandsOffs is a class that represents a hands-off event in a game. It has the following attributes:\n",
    " - `id`: a unique identifier for the hands-off event\n",
    " - `player_id`: the ID of the player who performed the hands-off\n",
    " - `timestamp`: the timestamp of the hands-off event\n",
    " - `game_id`: the ID of the game where the hands-off occurred\n",
    " - `game_state`: the state of the game at the time of the hands-off event\n",
    " - `hands_off_type`: the type of hands-off event (e.g. \"hands_off\",\n",
    " \"hands_off_by_opponent\", etc.)\n",
    " - `hands_off_reason`: the reason for the hands-off event (e.g. \"opponent's move\",\n",
    " \"player's move\", etc.)\n",
    " - `hands_off_target`: the target of the hands-off event (e.g. \"player\",\n",
    " \"opponent\", etc.)\n",
    " - `hands_off_target_id`: the ID of the target of the hands-off event\n",
    " - `hands_off_target_type`: the type of the target of the hands-off event (e.g . \"player\", \"opponent\", etc.)\n",
    " - `hands_off_target_name`: the name of the target of the hands-off event \n",
    " - `hands_off_target_position`: the position of the target of the hands-off event\n",
    " - `hands_off_target_position_x`: the x-coordinate of the target of the hands-off event\n",
    " - `hands_off_target_position_y`: the y-coordinate of the target of the hands-off event\n",
    " - `hands_off_target_position_z`: the z-coordinate of the target of the hands-off event\n",
    " - `hands_off_target_position_x_min`: the minimum x-coordinate of the target of the hands-off\n",
    " event\n",
    " - `hands_off_target_position_x_max`: the maximum x-coordinate of the target of the hands-off\n",
    " event\n",
    " - `hands_off_target_position_y_min`: the minimum y-coordinate of the target of the hands-off\n",
    " event\n",
    " - `hands_off_target_position_y_max`: the maximum y-coordinate of the target of the hands-off\n",
    " event\n",
    " - `hands_off_target_position_z_min`: the minimum z-coordinate of the target of the hands-off\n",
    " event\n",
    " - `hands_off_target_position_z_max`: the maximum z-coordinate of the target of the hands-off\n",
    " event\n",
    " - `hands_off_target_position_x_avg`: the average x-coordinate of the target of the hands-off\n",
    " event\n",
    " - `hands_off_target_position_y_avg`: the average y-coordinate of the target of the hands-off\n",
    " event\n",
    " - `hands_off_target_position_z_avg`: the average z-coordinate of the target of the hands\n",
    " off event\n",
    " - `hands_off_target_position_x_std`: the standard deviation of the x-coordinate of the target of\n",
    " the hands-off event\n",
    " - `hands_off_target_position_y_std`: the standard deviation of the y-coordinate of the target of\n",
    " the hands-off event\n",
    " - `hands_off_target_position_z_std`: the standard deviation of the z-coordinate of the target of\n",
    " the hands-off event\n",
    " - `hands_off_target_position_x_var`: the variance of the x-coordinate of the target of th\n",
    " hands-off event\n",
    " - `hands_off_target_position_y_var`: the variance of the y-coordinate of the target of th\n",
    " hands-off event\n",
    " - `hands_off_target_position_z_var`: the variance of the z-coordinate of the target of th\n",
    " hands-off event\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Instructions must be a string or a function, got {'diven a particular programming topic, your job is to help come up with a tutorial. You will do that by crafting an outline.after making the outline, hand it to the tutorial generator agent.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the context of OpenAI agents, \"handoff\" refers to transferring control or a task from one agent to another specialized agent. This is used to leverage the expertise of different agents to handle various aspects of a task. For instance, if a request is made that requires specific knowledge or capabilities, the original agent may hand off the request to a more specialized agent to provide a more accurate or detailed response.\n"
     ]
    }
   ],
   "source": [
    "from agents import Agent, Runner\n",
    "\n",
    "tutorial_generator = Agent(\n",
    "    name=\"Tutorial Generator\",\n",
    "    handoff_description= \"Specialist agent for Openai sdk agent building tutorials\",\n",
    "    instructions=(\n",
    "        \"Given a programing topic and an outline, your job is to generate code snippets for each section of the outline.\"\n",
    "        \"format the tutorial in markdowns using a mix of text for explanation and code snippts for examples.\"\n",
    "        \"where it makes sense, include comments in the code snippts to further explain the code.\",\n",
    "    )\n",
    "\n",
    ")\n",
    "\n",
    "outline_builder = Agent(\n",
    "    name= \"Outline Builder\",\n",
    "    handoff_description= \" Specialist agent for handoff\",\n",
    "    instructions={\n",
    "        \"diven a particular programming topic, your job is to help come up with a tutorial. You will do that by crafting an outline.\"\n",
    "        \"after making the outline, hand it to the tutorial generator agent.\"\n",
    "    },\n",
    "    handoffs=[tutorial_generator]\n",
    "    )\n",
    "tutorial_response = await Runner.run(outline_builder, \"What is handoff in openai agents\")\n",
    "print(tutorial_response.final_output)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Escalating to manager agent: Customer is unable to process a refund request online because the website displays as blank.\n",
      "Reason for escalation: The issue involves a potentially serious website malfunction that requires technical expertise beyond basic troubleshooting.\n",
      "Creating ticket for issue: Customer is unable to process a refund request online because the website displays as blank. Requires investigation of the website malfunction.\n",
      "I apologize for the inconvenience. A ticket has been created to address this issue with our technical team. Your ticket ID is 12345, and we will resolve this as soon as possible. Thank you for your patience.\n"
     ]
    }
   ],
   "source": [
    "from agents import function_tool, Agent, handoff, Runner\n",
    "from pydantic import BaseModel\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Step 1: Define escalation input model\n",
    "class ManagerEscalation(BaseModel):\n",
    "    issue: str\n",
    "    why: str\n",
    "\n",
    "# Step 2: Define tool\n",
    "@function_tool\n",
    "def create_ticket(issues: str):\n",
    "    print(f\"Creating ticket for issue: {issues}\")\n",
    "    return \"Ticket created ID: 12345\"\n",
    "\n",
    "# Step 3: Manager Agent\n",
    "manager_agent = Agent(\n",
    "    name=\"Manager Agent\",\n",
    "    handoff_description=\"Handles escalated issues that require managerial attention.\",\n",
    "    instructions=(\n",
    "        \"You handle escalated customer issues that the initial customer service agent could not solve. \"\n",
    "        \"You will receive the issue and the reason for escalation. If the issue cannot be immediately resolved for the customer, \"\n",
    "        \"create a ticket for the issue to be solved by the system admin and inform the customer.\"\n",
    "    ),\n",
    "    tools=[create_ticket],\n",
    ")\n",
    "\n",
    "# Step 4: Optional handoff callback\n",
    "def on_manager_handoff(ctx, input: ManagerEscalation):\n",
    "    print(\"Escalating to manager agent:\", input.issue)\n",
    "    print(\"Reason for escalation:\", input.why)\n",
    "\n",
    "# Step 5: Customer Service Agent\n",
    "customer_service_agent = Agent(\n",
    "    name=\"Customer Service Agent\",\n",
    "    instructions=(\n",
    "        \"You assist customers with general inquiries and basic troubleshooting. \"\n",
    "        \"If the issue cannot be resolved, you will escalate it to the manager along with the reason why you cannot fix the issue yourself.\"\n",
    "    ),\n",
    "    handoffs=[\n",
    "        handoff(\n",
    "            agent=manager_agent,\n",
    "            input_type=ManagerEscalation,\n",
    "            on_handoff=on_manager_handoff,\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Step 6: Main async call\n",
    "async def main():\n",
    "    result = await Runner.run(\n",
    "        customer_service_agent,\n",
    "        \"I want a refund , but your system won't let me process it. the website is just blank for me.\"\n",
    "    )\n",
    "    print(result.final_output)\n",
    "\n",
    "# Step 7: Call it properly in Jupyter\n",
    "await main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tracing\n",
    "\n",
    "a way to see what the code is doing at each step what agents are doing at each step.This is useful for debugging and understanding the behavior of the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Escalating to manager agent: Customer is unable to process a refund on the website as it appears blank.\n",
      "Reason for escalation: Technical troubleshooting of website issues is beyond my support capability.\n",
      "Creating ticket for issue: Customer is unable to process a refund on the website as it appears blank. Requires technical investigation to resolve website display issue for refund processing.\n",
      "I've created a ticket for your issue to be resolved by our technical team (Ticket ID: 12345). They will investigate the website problem and assist you with the refund as soon as possible. Thank you for your patience.\n"
     ]
    }
   ],
   "source": [
    "from agents import function_tool, Agent, handoff, Runner, trace  # ✅ now trace is imported\n",
    "from pydantic import BaseModel\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "class ManagerEscalation(BaseModel):\n",
    "    issue: str\n",
    "    why: str\n",
    "\n",
    "@function_tool\n",
    "def create_ticket(issues: str):\n",
    "    print(f\"Creating ticket for issue: {issues}\")\n",
    "    return \"Ticket created ID: 12345\"\n",
    "\n",
    "manager_agent = Agent(\n",
    "    name=\"Manager Agent\",\n",
    "    handoff_description=\"Handles escalated issues that require managerial attention.\",\n",
    "    instructions=(\n",
    "        \"You handle escalated customer issues that the initial customer service agent could not solve. \"\n",
    "        \"You will receive the issue and the reason for escalation. If the issue cannot be immediately resolved for the customer, \"\n",
    "        \"create a ticket for the issue to be solved by the system admin and inform the customer.\"\n",
    "    ),\n",
    "    tools=[create_ticket],\n",
    ")\n",
    "\n",
    "def on_manager_handoff(ctx, input: ManagerEscalation):\n",
    "    print(\"Escalating to manager agent:\", input.issue)\n",
    "    print(\"Reason for escalation:\", input.why)\n",
    "\n",
    "customer_service_agent = Agent(\n",
    "    name=\"Customer Service Agent\",\n",
    "    instructions=(\n",
    "        \"You assist customers with general inquiries and basic troubleshooting. \"\n",
    "        \"If the issue cannot be resolved, you will escalate it to the manager along with the reason why you cannot fix the issue yourself.\"\n",
    "    ),\n",
    "    handoffs=[\n",
    "        handoff(\n",
    "            agent=manager_agent,\n",
    "            input_type=ManagerEscalation,\n",
    "            on_handoff=on_manager_handoff,\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "# ✅ Use trace in async function\n",
    "async def main():\n",
    "    with trace(\"Customer Service Hotline\"):\n",
    "        result = await Runner.run(\n",
    "            customer_service_agent,\n",
    "            \"I want a refund , but your system won't let me process it. the website is just blank for me.\"\n",
    "        )\n",
    "        print(result.final_output)\n",
    "\n",
    "# ✅ Jupyter-friendly execution\n",
    "await main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Streaming\n",
    "\n",
    "streaming lets you create a stream of data from a file or other source. This can be useful for large files or for processing data in real-time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Run starting ===\n",
      "Agent updated: joker\n",
      "-- Tool was called\n",
      "-- Tool output: 2\n",
      "-- Message output:\n",
      "Here are two jokes for you:\n",
      "\n",
      "1. **Why did the scarecrow win an award?**\n",
      "   Because he was outstanding in his field!\n",
      "\n",
      "2. **Why don't scientists trust atoms?**\n",
      "   Because they make up everything!\n",
      "=== Run complete ===\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from agents import Agent, ItemHelpers, Runner, function_tool\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Tool: How many jokes\n",
    "@function_tool\n",
    "def how_many_jokes() -> int:\n",
    "    return random.randint(1, 5)\n",
    "\n",
    "# Agent: Joker\n",
    "agent = Agent(\n",
    "    name=\"joker\",\n",
    "    instructions=\"First call the 'how_many_jokes' tool, then tell that many jokes.\",\n",
    "    tools=[how_many_jokes],\n",
    ")\n",
    "\n",
    "# Run agent stream\n",
    "async def run_joker():\n",
    "    print(\"=== Run starting ===\")\n",
    "\n",
    "   \n",
    "    result = Runner.run_streamed(agent, input=\"Hello\")\n",
    "\n",
    "    # Now stream the events\n",
    "    async for event in result.stream_events():\n",
    "        if event.type == \"raw_response_event\":\n",
    "            continue\n",
    "        elif event.type == \"agent_updated_stream_event\":\n",
    "            print(f\"Agent updated: {event.new_agent.name}\")\n",
    "        elif event.type == \"run_item_stream_event\":\n",
    "            if event.item.type == \"tool_call_item\":\n",
    "                print(\"-- Tool was called\")\n",
    "            elif event.item.type == \"tool_call_output_item\":\n",
    "                print(f\"-- Tool output: {event.item.output}\")\n",
    "            elif event.item.type == \"message_output_item\":\n",
    "                print(f\"-- Message output:\\n{ItemHelpers.text_message_output(event.item)}\")\n",
    "    print(\"=== Run complete ===\")\n",
    "\n",
    "# ✅ Run it in notebook\n",
    "await run_joker()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Run starting ===\n",
      "Agent updated: Joker\n",
      "-- Tool was called\n",
      "-- Tool output: 2\n",
      "-- Message output:\n",
      " Here are two jokes for you:\n",
      "\n",
      "1. Why did the scarecrow win an award?  \n",
      "   Because he was outstanding in his field!\n",
      "\n",
      "2. What do you call fake spaghetti?  \n",
      "   An impasta!\n",
      "=== Run complete ===\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from agents import Agent, ItemHelpers, Runner, function_tool\n",
    "\n",
    "@function_tool\n",
    "def how_many_jokes() -> int:\n",
    "    return random.randint(1, 10)\n",
    "\n",
    "agent = Agent(\n",
    "    name=\"Joker\",\n",
    "    instructions=\"First call the `how_many_jokes` tool, then tell that many jokes.\",\n",
    "    tools=[how_many_jokes],\n",
    ")\n",
    "\n",
    "result = Runner.run_streamed(\n",
    "    agent,\n",
    "    input=\"Hello\",\n",
    ")\n",
    "print(\"=== Run starting ===\")\n",
    "\n",
    "async for event in result.stream_events():\n",
    "    # We'll ignore the raw responses event deltas\n",
    "    if event.type == \"raw_response_event\":\n",
    "        continue\n",
    "    # When the agent updates, print that\n",
    "    elif event.type == \"agent_updated_stream_event\":\n",
    "        print(f\"Agent updated: {event.new_agent.name}\")\n",
    "        continue\n",
    "    # When items are generated, print them\n",
    "    elif event.type == \"run_item_stream_event\":\n",
    "        if event.item.type == \"tool_call_item\":\n",
    "            print(\"-- Tool was called\")\n",
    "        elif event.item.type == \"tool_call_output_item\":\n",
    "            print(f\"-- Tool output: {event.item.output}\")\n",
    "        elif event.item.type == \"message_output_item\":\n",
    "            print(f\"-- Message output:\\n {ItemHelpers.text_message_output(event.item)}\")\n",
    "        else:\n",
    "            pass  # Ignore other event types\n",
    "\n",
    "print(\"=== Run complete ===\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
